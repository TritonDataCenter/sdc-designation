---
title: Joyent Engineering Guide
markdown2extras: wiki-tables, code-friendly
---

# Joyent Engineering Guide

This document describes standards and best practices for software development at
Joyent. These standards are intended to maintain product quality and to provide
consistency across codebases to make it easier for all engineers to learn new
parts of the system. This latter goal is important to encourage everyone to feel
comfortable diving into all parts of the system, as is often necessary when
debugging.

It's important to remember that all situations are unique, so rules should not
be followed blindly. However, these guidelines represent the best practices
agreed upon by the team. If you feel it necessary to diverge from them, that's
okay, but be prepared to explain why.

Note: In this document, services implementing an API are referred to as APIs.
For example, "MAPI" denotes the service implementing the MAPI API.


# Repository Guidelines

These guidelines cover naming, structure, and processes around repositories.
A template repository is included in this repo so you can quickly get something
working that follows these guidelines.


## Rule #1: FCS Quality All the Time

In general, use the "master" branch for development and releases. **"master"
must be FCS (First Customer Ship) quality at all times.** Although releases are
technically cut from release-specific branches, these branches are not expected
to diverge significantly from "master" at the time the branch was cut except
for fixes backported after the cut. That is, development should not be ongoing
in the release branches.

When working on large features, it's tempting to use development branches that
eventually get integrated into master. Indeed, this is sometimes necessary.
However, it should be avoided when possible, as it means people are running dev
branches rather than "master", which can lead to a [quality death spiral
(QDS)](http://hub.opensolaris.org/bin/view/Community+Group+on/qual_death_spiral)
as fewer people actually run the mainline tree. Where possible, consider
whether larger projects can be split into reasonably-sized chunks that can
individually be integrated into "master" without breaking existing
functionality. This allows you to continue developing on "master" while still
being able to commit frequently.


## Repository Naming

For repositories representing an API, the repo name that matches how the API is
discussed (spoken, chatted and emailed) means you'll get the repo name right on
first guess. If you can get away with it, a repo named after the abbreviate API
name is best. For example:
    
    Network API -> NAPI -> napi.git          # Good.
                        -> network-api.git   # Less good.
                        -> network_api.git   # Even less good.
                        -> NAPI.git          # Whoa! Capital letters are crazy here.


## Language

New server-side projects should almost certainly use Node.js with C/C++
components as needed. Consolidating onto one language makes it easier for
everyone to dig into other teams' projects as needed (for development as well
as debugging) and allows us to share code and tools.


## Directory Layout

Here is a suggested directory/file structure for your repository. All
repos **must** have a `README.md` and `Makefile`. The others are suggested
namings for particular usages, should your repo require them.

    build/          Built bits.
    deps/           Git submodules and/or commited 3rd-party deps should go
                    here. See "node_modules/" for node.js deps.
    docs/           Project docs. Uses restdown and man.
    lib/            JavaScript source files.
    node_modules/   Node.js deps, either populated at build time or commited.
                    See Managing Node Dependencies.
    pkg/            Package lifecycle scripts
    smf/manifests   SMF manifests
    smf/methods     SMF method scripts
    src/            C/C++ source files.
    test/           Test suite. node-tap prefered.
    tools/          Miscellaneous dev/upgrade/deployment tools and data.
    Makefile        See below.
    package.json    npm module info, if applicable (holds the project version)
    README.md       See below.


"docs" or "doc"? "test" or "tst"? We're not being religious about the
directory names, however the Makefile target names should use the names
specified below to allow automated build tools to rely on those names. The
reason to suggest "docs" and "test" as the directory names is to have the
same name as the Makefile targets.


### README.md

Every repository **must** have in its root a README.md (Markdown) file that
describes the repo and covers:

* the name of the API or other component(s) contained in the repo and a brief
  description of what they do
* the JIRA project for this repo (and any additional instructions, like how JIRA
  components are used for this project)
* owners of the project
* the style and lint configurations used, any additional pre-commit checks, and
  any non-standard useful Makefile targets
* some overview of the structure of the project, potentially including
  descriptions of the subcomponents, directory structure, and basic design
  principles
* basic development workflow: how to run the code and start playing with it

It's strongly recommended to start with the template in this repo.


### Makefile

All repos **must** have a Makefile that defines at least the following targets:

* `all`: builds all intermediate objects (e.g., binaries, executables, docs,
  etc.). This should be the default target.
* `check`: checks all files for adherence to lint, style, and other
  repo-specific rules not described here.
* `clean`: removes all built files
* `prepush`: runs all checks/tests required before pushing changes to the repo
* `docs`: builds documentation (restdown, man pages)
* `test`: runs the automated test suite
* `release`: build releasable artifacts, e.g. a tarball (for projects that
  generate release packages)

The `check` and `test` targets **must** fail if they find any 'check'
violations or failed tests. The `prepush` target is intended to cover all
pre-commit checks.  It **must** run successfully before any push to the repo.
It **must** also be part of the automated build. Any commit which introduces a
prepush failure **must** be fixed immediately or backed out. A typical prepush
target will look like the following, but some non-code repositories might
differ (e.g. not have a test suite):

    prepush: check test
            @echo "Okay to push."


## Coding Style

Every repository **must** have a consistent coding style that is enforced by
some tool. It's not necessary that all projects use the same style, though it's
strongly suggested to keep differences to a minimum (e.g., only hard vs. soft
tabs and tabstops). All styles **must** limit line length to 80 columns.
Existing style-checking tools include:

* C: [cstyle](https://github.com/joyent/illumos-joyent/blob/master/usr/src/tools/scripts/cstyle.pl)
* JavaScript: [jsstyle](https://github.com/davepacheco/jsstyle), [gjslint](https://code.google.com/closure/utilities/docs/linter_howto.html)
* Bash: bashstyle (contained in eng.git:tools/bashstyle)
* Makefiles: use bashstyle for now

Both cstyle and jsstyle (which are 90% the same code) support overriding style
checks on a per-line basis (e.g., for literal regular expressions). Feel free
to add options to these tools to allow for flexibility, as in tabs vs. spaces.
You can also write your own tool.

Note that gjslint can be used as a style checker, but it is **not** a
substitute for javascriptlint. And as with all style checkers, it **must** be
integrated into `make check`.

Bash scripts and Makefiles must also be checked for style. The only style
guideline for now is the 80-column limit.

Make target: "check"

*Note: It is understood that `jsstyle` currently isn't configurable for all
the current common JavaScript styles in Joyent repositories. Adding support
for those styles to jsstyle (or a separate tool) should be done, but
prioritize accordingly with actual product work.*


## Lint

Every C repository **must** run "lint" and every JavaScript repository **must**
run [javascriptlint](http://github.com/davepacheco/javascriptlint) and both
**must** be lint-clean. Note that lint is not the same as style: lint covers
objectively dangerous patterns like undeclared variables, while style covers
subjective conventions like spacing.

Both lint and javascriptlint are very configurable. Projects may choose to
enable and disable particular sets of checks as they deem appropriate.  Most
checks can be disabled on a per-line basis. As with style, it's recommended
that we minimize divergence between repositories.

Make target: "check" 


## Copyright

All source files (including Makefiles) should have a copyright statement that
says:

    Copyright (c) [year], Joyent, Inc. All rights reserved.

Year should be exactly the latest year when the file was changed, not a list or
range of years. For example:

    Copyright (c) 2012, Joyent, Inc. All rights reserved.


## Testing

All repos **must** include a comprehensive automated test suite, preferably
using node-tap. Bug fixes and new features should not be integrated without
considering adding new tests.

Make target: "test"

## cscope

cscope is a terminal-based tool for browsing source. For performance, it's best
to use it with an index. For repos using this repo's Makefile, you can build a
basic index in a source tree using:

    # make xref

which translates to:

    # cscope -bqR

To browse the source after the index is built, use:

    # cscope -dq

cscope is available for SmartOS in pkgsrc. It's also buildable on MacOS. For
instructions, see [the
wiki](https://hub.joyent.com/wiki/display/dev/Snow+Leopard+tips%2C+fixes+and+bugs).

Make target: "xref"

## Documentation

### API Documentation

You **must** use [restdown](https://github.com/trentm/restdown). Please discuss
with Trent if this isn't workable for your project.

Restdown is a tool for creating docs (and especially REST API docs) using a
single Markdown file with a few added conventions. You can set it up as
follows. Get the restdown tool:

    git submodule add git://github.com/trentm/restdown.git deps/restdown
    cd deps/restdown/
    git checkout 1.2.15    # let's use a restdown release tag

Get a starter restdown file:

    mkdir -p docs/media/img
    cp ../eng/docs/boilerplateapi.restdown docs/index.restdown
    cp ../eng/docs/media/img/favicon.ico docs/media/img/
    cp ../eng/docs/media/img/logo.png docs/media/img/

Tell the Makefile about it (`make docs`):

    DOC_FILES = docs/index.restdown

TODO: Finish off static serving of the docs in server.js.


### Code Documentation

Consider adding a block comment at the top of every file that describes at a
high level the component that's implemented in the file. For example:

    /*
     * ca-profile.js: profile support
     *
     * Profiles are sets of metrics.  They can be used to limit visibility of
     * metrics based on module, stat, or field names, or to suggest a group of
     * metrics to a user for a particular use case.
     */

For non-trivial subsystems, consider adding a Big Theory statement that
describes what the component does, the external interface, and internal details.
For a great example, check out
[panic.c](https://github.com/joyent/illumos-joyent/blob/master/usr/src/uts/common/os/panic.c#L29)
in the kernel.

Consider keeping design documents in restdown inside the repo. It's okay to have
one-off documents for specific projects, even if they become out of date as the
code evolves, but make clear in the document that the content may be out of
date. Keep such docs separate from general design documents that are kept up to
date.


### Man Pages

XXX use ronn. Is ronnjs acceptable now? If so, document then and add examples.
XXX use normal man page syntax for existing repos (illumos-joyent)


## Managing Node Dependencies

There are several ways of managing Node dependencies, each with notable pros
and cons. Choose whatever method works best for you, but try to be consistent
within a given repo. Either way, "make all" and other "make" targets should
automatically take care of setting up dependencies as needed.

With any of these methods, beware that the build process **must not** use
external resources because they cannot be trusted and may not even be
available.

*Note: From the length of this section, it should be obvious that this
isn't full baked yet. We need some more experience.*

### Method 1: Commit node_modules to Git

In short: `npm install` to install all your deps, `git add node_modules`,
and commit. For binary modules: exclude binary bits and use `npm rebuild`
at build time.

This should be simple and easy to manage. However there are some remaining
questions on implementing this in general:

- Are there difficulties with the `git add node_modules` due to .gitignore
  files in the deps? "node_modules" is a common entry in many node modules'
  .gitignore files. Perhaps just deleting them all is sufficient
  (.npmignore vs. .gitignore).
- Do "devDependencies" get in the way here? Presumably we wouldn't commit
  dev dependencies. Perhaps specific "node_modules/my-dev-dep" entries
  in ".gitignore" would suffice.
- TODO: spec the .gitignore entries to facilitate excluding binary bits
  in the `git add node_modules`.

One downside with this approach is that there's nothing to enforce that the
committed source actually matches what it's supposed to (i.e. and hasn't been
inadvertently changed). This isn't likely to be an issue as engineers *should*
know that source in node_modules is not original and must not be modified
directly.

One suggestion for the "floating patches" is to create a fork of the module
(e.g.  [trentm-datetime](http://search.npmjs.org/#/trentm-datetime) for
[datetime](http://search.npmjs.org/#/datetime)) until patches are released
upstream.

### Method 2: Git Submodules for Sources

Use git submodules to get the source for all dependent packages,
`git submodule add git://github.com/bob/my-dep.git deps/my-dep`, and either
reference the dependency's source directly or use `npm install deps/my-dep` at
build time.  This avoids the potential inconsistency problem described above,
but it's unclear how this can be generalized for dependencies with their own dependencies. Also, git submodules are somewhat clumsy.

### Method 3: List Specific Versions

List specific versions (e.g., "1.2.3" not "1.2") for all deps **and all deps
of deps** in your top-level "package.json". Then `npm install` to get
specific versions of everything. You can check this by making sure there are
no "node_modules/*/node_modules" directories.  This method requires vigilance
when adding new dependencies, though that could be automatically checked as
part of "make prepush". Another problem is that this method cannot support two different versions of a given module (used by different dependencies).

The "./tools/npmfreeze.js" tool in this repo can help you put together the list
of versions.



## Commit Comments and JIRA Tickets

In collaborating on a body of software as large as SDC, it's critical that the
issues and thought processes behind non-trivial code changes be documented,
whether that's through code comments, git commit comments, or JIRA tickets.
There are many cases where people other than the original author need to
examine the git log:

* An engineer in another area tries to understand a bug they've run into (in
  your repo or not), possibly as a result of a recent change. The easier it is
  for people to move between repos and understand recent changes, the more
  quickly bugs in master can be root-caused. This is particularly important to
  avoid an issue bouncing around between teams where the problem is *not*.
* An engineer in another area tries to understand when a feature or bugfix
  was integrated into your repo so that they can pull it down to use it.
* An engineer working on the same code base, possibly years later, needs to
  modify (or even rewrite) the same code to fix another bug. They need to
  understand why a particular change was made the way it was to avoid
  reintroducing the original bug (or introducing a new bug).
* A release engineer tries to better understand the risk and test impact of a
  change to decide whether it's appropriate to backport.
* A support engineer tries to better understand the risk and test impact of a
  change to decide whether it's appropriate for binary relief or hot patching.
* Product management wants to determine when a feature or bugfix was integrated.
* Automated tools want to connect commits to JIRA tickets.

To this end, we require that with every commit there **must** be a comment that
includes the list of JIRA tickets addressed with this commit and a synopsis of
the changes (*either* for the whole commit *or* for each change, one by one).
**Between the JIRA ticket and the commit comment itself, there must be
sufficient information for an engineer that's moderately familiar with the code
base, possibly years later but with source in hand, to understand how and why
the change was made.**

The worst case is when the thought process and issue list are nowhere: not in
the comments and not in the JIRA tickets.

### Commit Comments

Across Joyent we require that **each commit be associated with one or more JIRA
tickets and that those tickets be listed in the commit comments**. This way,
given either the commit or the JIRA ticket, one can find the other.

Historically, some repos (notably illumos-joyent and cloud-analytics) have
additionally required that tickets must not be reused for multiple commits in
the same repo except for very minor changes like fixing lint or style warnings.
This makes it easier to correlate tickets and commits, since there's usually
exactly one commit for each resolved ticket. It also makes it easier to
back out the changes for a particular project. For these repos, the git
comments for the commit consist of a single line per JIRA ticket being resolved
in the commit. Each line consists of the ticket identifier and the synopsis
exactly as it appears in JIRA (optionally truncated to 80 characters with
"..."):

    OS-147 vfsstat command to show VFS activity by zone
    OS-148 Update ziostat to coexist peacefully with vfsstat
    OS-149 New kstats to support vfsstat

This approach encourages short, descriptive ticket synopses. For repos that keep
track of code reviews (e.g., illumos-joyent), that information is appended like
this:

    OS-850 Add support for Intel copper quad I350 to igb.
    Reviewed by: Jerry Jelinek <jerry.jelinek@joyent.com>

In the rare cases where the same ticket is used for multiple commits, a
parenthetical is used to explain why:

    INTRO-581 move mdb_v8 into illumos-joyent (missing file)

This structure works well for established repos like illumos, but it's not
always appropriate. For new work on greenfield projects, it may not even make
sense to use more than one ticket until the project reaches a first milestone.

### JIRA Tickets

For bugs, especially those that a customer could hit, consider including
additional information in the JIRA ticket:

* An explanation of what happened and the root cause, referencing the source
  where appropriate. This can be useful to engineers debugging similar issues
  or working on the same area of code who want to understand exactly why a
  change was made.
* An explanation of how to tell if you've hit this issue. This can be pretty
  technical (log entries, tools to run, etc.). This can be useful for engineers
  to tell if they've hit this bug in development as well as whether a customer
  has hit the bug.
* A workaround, if any.

Of course, much of this information won't make sense for many bugs, so use your
judgment, but don't assume that you're the only person who will ever look at the
ticket.

# Logging (DRAFT)

**Note: this section is still under heavy revision.**

There are at least three different consumers for a service's logs:

- engineers debugging issues related to the service (which may not actually be
  problems with the service)
- monitoring tools that alert operators based on error events or levels of
  service activity
- non real-time analysis tools examining API activity to understand performance
  and workload characteristics and how people use the service

For the debugging use case, **the goal should be to have enough information
available after a crash or an individual error to debug the problem from the
very first occurrence in the field**. It should also be possible for engineers
to manually dump the same information as needed to debug non-fatal failures.

Logs intended for humans may be plain text or structured (for processing by
tools that will present the logs to people), but logs intended for machines
**must** be formatted in
[JSON](http://journal.paul.querna.org/articles/2011/12/26/log-for-machines-in-json/),
which we'll call sdclog format.

Multiple use cases do not require multiple log files.  Most services should log
all activity (debugging, errors, and API activity) in JSON to either the SMF
log or into a separate log file in
/var/smartdc/&lt;service&gt;/logs/&lt;component&gt;.sdclog. For services with
extraordinarily high volume for which it makes sense to separate out API
activity into a separate file, that should be directed to
/var/smartdc/&lt;service&gt;/logs/requests.sdclog However, don't use separate
log files unless you're sure you need it.  All log files in
/var/smartdc/&lt;service&gt;/logs should be configured for appropriate log
rotation.

For any log entries generated while handling a particular request, the log
entry **must** include the request id. See "Request Identifiers" under "REST
API Guidelines" below.

**Note: we will be providing a common logging facility for logging in Node
programs, but it's not yet available.**

The following JSON keys should be used in log messages:

|| **JSON key** || **Description** || **Examples** || **Required** ||
|| **time** || Date/time of event in [W3C DTF](http://www.hackcraft.net/web/datetime/#w3cdtf) format using UTC: `YYYY-MM-DDThh:mm:ss.sssZ` || "2012-01-26T19:20:30.450Z" || All entries ||
|| **hostname** || Server hostname || `uname -n` || All entries ||
|| **facility** || Service name || "ca" (for Cloud Analytics) || All entries ||
|| **component** || Service component || "aggregator-12" || All entries for services with multiple components ||
|| **type** || Used for different types of messages from the same service || "debug", "request" || All entries as desired ||
|| **severity** || Log level. || "fatal", "error", "warn", "info", or "debug" || Entries with "type" == "debug" ||
|| **request_id** || String request identifier || See "Request Identifiers" under "REST API Guidelines" below. || All entries relating to a particular request ||
|| **short_message** || Short human- and machine-readable message || "illegal argument error" || Entries with "type" == "debug" ||
|| **full_message** || Human-readable message || "illegal argument: parameter \'retention-time\' must be numeric" || Entries with "type" == "debug" ||
|| **latency** || Time of request in milliseconds || 155 || Entries describing the completion of a request or other backend operation ||
|| **http_method** || HTTP method || "GET" || Entries describing an HTTP request ||
|| **http_uri** || HTTP URL path (not including querystring) || "/instrumentations/10" || Entries describing an HTTP request ||
|| **http_qstring** || HTTP URL querystring || "?foo=bar" || Entries describing an HTTP request ||
|| **http_headers** || HTTP headers || `\{ "content-length": 5278 \}` || Entries describing an HTTP request ||
|| **http_user** || Authenticated user name || "dap" || Entries describing an HTTP request ||
|| **http_body** || HTTP request body || arbitrary || Entries describing an HTTP request where the body may be significant (e.g., contain request parameters) and will not be very large (as for most REST services) ||
|| **http_status** || HTTP status code || 200 || Entries describing the completion of an HTTP request ||

The hostname and facility should be included in all entries so that logs are
self-contained. This makes them substantially easier to move (e.g., via support
bundles) and then aggregate.

We use these definitions for log severity levels:

- "fatal": the service is going to stop or become unusable now
- "error": fatal for a particular request, but the service continues servicing other requests
- "warn": a note on something that should probably be looked at by an operator
- "info": detail on regular operation
- "debug": anything else, i.e. too verbose to be included in "info" level.

"debug" should be used sparingly. Information that will be useful to debug
errors *post mortem* should usually be included in "info" messages if it's
generally relevant or else with the corresponding "error" event. Don't rely on
spewing mostly irrelevant debug messages all the time and sifting through them
when an error occurs.

Most of the time, different services should log to different files. But in some
cases it's desirable for multiple consumers to log to the same file, as for
vmadm and vmadmd. For such cases, syslog is an appropriate choice for logging
since it handles synchronization automatically. Care must be taken to support
entries longer than 1024 characters.

# SMF Integration

All services **must** be delivered as SMF services. This means:

- They deliver an SMF service manifest.
- The install mechanism imports the manifest.
- The uninstall mechanism deletes the service.
- The service is started, stopped, restarted, etc. via SMF.

While SMF itself is grimy and the documentation is far from perfect, the
documentation *is* extensive and useful. Many common misunderstandings about
how SMF works are addressed in the documentation. It's strongly recommended
that you take a pass through the docs before starting the SMF integration for
your service. In order of importance, check out:

- SMF concepts: smf(5), smf_restarter(5), smf_method(5), svc.startd(1M)
- Tools: svcs(1), svcadm(1M), svccfg(1M)

Common mistakes include:

- Setting the start method to run the program you care about (e.g., "node
  foo.js") rather than backgrounding it (e.g., "node foo.js &"). SMF expects
  the start method to start the service, not *be* the service. It times out
  start methods that don't complete, so if you do this you'll find that your
  service is killed after some default timeout interval. After this happens
  three times, SMF moves the service into maintenance.
- Using "child" or "wait model" services to avoid the above problem. Read the
  documentation carefully; this probably doesn't do what you want. In
  particular, if your "wait model" service fails repeatedly, SMF will never put
  it into maintenance. It will just loop forever, forking and exiting.
- Not using "-s" with svcadm enable/disable. Without "-s", these commands are
  asynchronous, which means the service may not be running when "svcadm enable"
  returns. If you really care about this, you should check the service itself
  for liveness, not rely on SMF, since the start method may have completed
  before the service has opened its TCP socket (for example).

## Managing processes under SMF

SMF manages processes using an OS mechanism called contracts. See contract(4)
for details. The upshot is that it can reliably tell when a process is no
longer running, and it can also track child processes.

Quoting svc.startd(1M):

     A contract model service fails if any of the following conditions
     occur:

         o    all processes in the service exit

         o    any processes in the service produce a core dump

         o    a process outside the service sends a service process a
              fatal signal (for example, an administrator terminates a
              service process with the pkill command)

Notice that if your service forks a process and *that* process exits,
successfully or otherwise, SMF will not consider that a service failure. One
common mistake here is forking a process that will be part of your service, but
not considering what happens when that process fails (exits). SMF will not
restart your service, so you'll have to manage that somehow.

## Service logs

SMF maintains a log for each service in /var/svc/log. The system logs restarter
events here and launches the start method with stderr redirected to the log,
which often means the service itself will have stderr going to this log as
well. It's recommended that services either use this log for free-form debug
output or use the standard logging facility described under "Logging" above.

# REST API Guidelines

It's strongly recommended to use
[restify](https://github.com/mcavage/node-restify) for all web services. Not
only will you leverage common code and test coverage, but restify gives you
features like DTrace observability, debuggability, throttling, and versioning
out of the box. If it doesn't support something you need, consider adding it
rather than rolling your own.

## Request Identifiers

A request identifier uniquely identifies an operation across multiple services
(e.g., portal, cloudapi, ca, ufds). It's essential for debugging issues after
they've happened. The goal is for issues to be debuggable from the information
available after their first occurrence, without having to reproduce it to
gather more information. To facilitate this:

- When an external service receives a request from the outside, it **must**
  generate a unique request identifier and include it in the "x-request-id"
  header of any requests made as part of handling the initial request.
- When any service receives a request with an "x-request-id" header, it
  **must** include it in the "x-request-id" header of any request made as part
  of handling that request.
- When each service logs activity (API requests), alerts, or debug messages
  related to a particular request, it **must** include the request id.

## XXX Naming Endpoints

TODO: codify some of MarkC's and my (mostly mark) discussions on naming of
API endpoints.

# Miscellaneous Best Practices

- Use JSON for config data. Not ini files: iniparser module has bugs, there
  are always questions about encoding non-string values.
- For services and distributed systems, consider building rich tools to
  understand the state of the service, like lists of the service's objects and
  information about each one. Think of the SmartOS proc(1) tools (see man pages
  for pgrep, pstack, pfiles, pargs).
- Consider doing development inside a SmartOS zone rather than on your Macbook
  or a COAL global zone. That forces us to use our product the way customers
  might, and it eliminates classes of problems where the dev environment doesn't
  match production.
- Whether you develop in COAL or on your Macbook, document what's necessary to
  get from scratch to a working development environment so that other people can
  try it out. Ideally, automate it. Having a script is especially useful if you
  do develop on COAL, which also forces you to keep it up to date.
- Similarly, build tools to automate deploying bits to a test system (usually a
  SmartOS headnode zone). The easier it is to test the actual deployment, the
  more likely people will actually test that, and you'll catch environment
  issues in development instead of after pushing.


# Examples

- The [boilerplate API](boilerplateapi.html) example in this repo gives you a
  starter file and some suggestions on how to document a web service.

